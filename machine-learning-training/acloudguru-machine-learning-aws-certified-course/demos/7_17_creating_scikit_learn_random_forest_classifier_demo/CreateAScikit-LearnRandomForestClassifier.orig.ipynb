{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A Cloud Guru](acg_logo.png)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Create a Random Forest Classifier Using scikit-learn</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|![Sparky](sparky.png)|![Penny](penny.png)|\n",
    "|:-------------------:|:-------------------:|\n",
    "|Sparky the Dog|Penny the Cat|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bab978a4d9bc483f0697223cca084e52213fdf00"
   },
   "source": [
    "<center><h2>Are You Likely to Be a Dog Person or a Cat Person?</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this lab, we take a quick look at __scikit-learn__, a machine learning framework.\n",
    "\n",
    "Designed to be native to Python, scikit-learn contains various classification, regression, and clustering algorithms, including __random forests__ which we use in this lab.\n",
    "\n",
    "# Scenario\n",
    "\n",
    "You run a local pet store, and you want to know what kind of products to recommend to new customers. You've contracted a survey company to collect information on 199 of your current customers, including if they think themselves to be 'dog people' or 'cat people'. The questions the survey asked were:\n",
    "\n",
    "- Do you like walking?\n",
    "- Do you like running?\n",
    "- What is your favorite color?\n",
    "- How many miles do you walk in a day?\n",
    "- Do you like dogs or cats?\n",
    "\n",
    "Clearly this is a fictitious dataset. If this were real, you'd fire the survey company!\n",
    "\n",
    "We're going to use a random forest algorithm trained with our survey data to build a model that classifies new customers as dog or cat people.\n",
    "\n",
    "We do this using standard Python libraries such as NumPy, Pandas, and matplotlib along with scikit-learn.\n",
    "\n",
    "## scikit-learn\n",
    "### Machine Learning in Python\n",
    "\n",
    "- Simple and efficient tools for data mining and data analysis.\n",
    "- Accessible to everybody and reusable in various contexts.\n",
    "- Built on NumPy, SciPy, and matplotlib.\n",
    "- Open source and commercially usable - BSD license.\n",
    "\n",
    "_(Source: https://scikit-learn.org/)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use This Lab\n",
    "\n",
    "All of the code is provided for you in this lab as our solution to the tasks presented. You could simply execute the notebook to get a result, but that's not really very hands-on and it won't teach you anything but how to execute cells in a Jupyter notebook. To get the most from this lab, you should understand what the code in each cell is trying to accomplish, and then take the time to experiment: make changes, break it, fix it, and learn! You can always pull the code down again to get a clean copy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)  Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sn\n",
    "#Use a magic command to display the graphs better\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the random seed to have reproducible results\n",
    "np.random.seed(42)\n",
    "\n",
    "# These two includes help us render a graph\n",
    "from subprocess import call\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "78d63e79cfb6f48e78dab7c785e8e952a08d518c"
   },
   "source": [
    "# 2) Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset created from a set of people who either liked dogs or cats. Clearly this is a fictional dataset and some of the data is useless. But let's see what we can learn from it.\n",
    "\n",
    "First we load the data. Pandas provides a very convenient way of loading CSV data, which is what our survey results are stored as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# TODO: Import the data.csv file into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first few rows of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should check to see what data types it's using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d9071ced2d8af54afece86069d15189a73b57198"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first data preparation, let's change the names of some of the columns, including marking ```dogs_cats``` as an out label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f3caf3de0a7e6d4602b26a1e72bf42d42ef0aac0"
   },
   "outputs": [],
   "source": [
    "df.columns = ['walk', 'run', 'color', 'distance', 'label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is not shuffled very well. We see a lot of similar information, so we didn't learn much. We don't want to look at the rest of our data individually to improve our understanding. Rather, we want to describe the data as a whole. Let's have Pandas tell us more about the data statistically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6719808a43af6e2a70306d22c9107d4201bd8953"
   },
   "source": [
    "For our next data preparation step, let's format the data in the columns so the model will understand it better. \n",
    "\n",
    "Despite the `walk`, `run`, and `label` columns being integers, they are actually representing a binary value, 1 or 0. For `walk` and `run`, this corresponds to True or False for liking that activity. For `label`, this represents whether you prefer cats or dogs. Instead of using integers, let's change these fields to the boolean data type.\n",
    "\n",
    "`color_type` is not random text. It actually represents one of three categories (red, green, or blue). Instead of treating it as text, let's change it to a categorical data type.\n",
    "\n",
    "Note that we are not modifying distance. The question value it represents asks for a number, and it currently is a number. No change needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "12edd841e271a4f7c8c039aa73412c0d6d7e5dad"
   },
   "outputs": [],
   "source": [
    "# TODO: Set the Data types for each of our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "55c1d2d27385000bb2c9fc24bde9e4278427d507"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "322dc81858a93b4ddc868d8f2ab930fbdbaef966"
   },
   "source": [
    "The algorithm will not understand color as a list of strings. With the data as it is now, we can expect to get the following error when we trt to fit the data:\n",
    "`ValueError: could not convert string to float: 'green'`\n",
    "So we use the `get_dummies` command to perform a one hot encoding process directly into the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b6ec4deb644854301fa463758df32d6171f1c615"
   },
   "outputs": [],
   "source": [
    "# TODO: Perform one-hot encoding of our `colors` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With data formatting complete, let's take a quick look at what our data looks like now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b7e5dbbfb3ac0c50881317ec9148cd60f8593def"
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "771e4a2e2c9c25b99fee912eee47c97c6cb3b1cc"
   },
   "source": [
    "<a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last data preparation task is to split the data into training and testing sets. We use scikit-learn's `train_test_split` to split off 20% of the data for testing so we have 80% for training. We also set `random_state` so that we'll have a random, but repeatable, data split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "315ebc70bfe105f4b224974415db867d3d1e6b66"
   },
   "outputs": [],
   "source": [
    "# TODO: Split the dataset into 80% Training, and 20% Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58c7f30375a2ffb7e02763e249e441a12cd437f1"
   },
   "source": [
    "# 3) Create the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time has come to create the model. We're going to create a `RandomForestClassifier` moodel. We set one parameter, but there are many more options for tweaking your model. You can read about them in the [Random Forest Classifier documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6169b0b96267bea8bd8c35d64470d634edd79d78"
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we `fit` the model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit the model to use our training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 199 survey responses, this trains very quickly. Now, let's see what we got."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we grab the estimator from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ba57c6d01b0c052d84a8555f25112e171cb87b69"
   },
   "outputs": [],
   "source": [
    "estimator = model.estimators_[0]\n",
    "feature_names = [i for i in X_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use ```export_graphviz``` to get a graphical representation of __one of__ the trees in our forest. __After this code block has run, wait a moment for the graph to appear.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0b8e83b26ca2de7f8db94154f27fabd5e231ed7d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "export_graphviz(estimator, out_file='tree.dot',\n",
    "                feature_names = feature_names,\n",
    "                rounded = True,\n",
    "                filled = True)\n",
    "\n",
    "# Use CLI Graphviz to create a png file from our graph data:\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "\n",
    "Image(filename = 'tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6773e207b1fbf84352462d6889fa52d3ecfb90bb"
   },
   "source": [
    "Now let's run our testing data through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c215bcb6b80e12905f54b6a33620b6514d1e915a"
   },
   "outputs": [],
   "source": [
    "# TODO: Use the Testing dataset to produce the first predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6e690433e6cd2bc181f5af0d514274f29fe502bf"
   },
   "source": [
    "To see how it performed, let's use ```confusion_matrix``` to create a confusion matrix for the test data predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a0fe6269405b8404a60fd656ee2940f50cc4c0d3"
   },
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_predict)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not very easy to read. Let's add some style to it using the `seaborn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "cleaned_conf_matrix = np.array([[tp, fp], [fn, tn]])\n",
    "y_true = [\"Dog\", \"Cat\"]\n",
    "df_cm = pd.DataFrame(cleaned_conf_matrix, columns=y_true, index=y_true)\n",
    "df_cm.index.name = 'Predicted'\n",
    "df_cm.columns.name = 'Actual'\n",
    "\n",
    "df_cm.dtypes\n",
    "\n",
    "plt.figure(figsize = (8,5))\n",
    "plt.title('Confusion Matrix')\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(df_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16})# font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from the confusion matrix, let's calculate **sensitivity** and **specificity**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fcd6e81d7fdfae6571aee37f210cbd6f15da1a8a"
   },
   "outputs": [],
   "source": [
    "sensitivity = tp / (tp + fn)\n",
    "print('Sensitivity : ', sensitivity )\n",
    "\n",
    "specificity = tn / (tn + fp)\n",
    "print('Specificity : ', specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c5e22af3bc387bc958407153cc6c9d26f56f0a4"
   },
   "source": [
    "Now let's look at the __ROC__ graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82e957d065f62731292b9aac5ae97b4a06471857"
   },
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr)\n",
    "ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for Dog vs Cat people')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8ed12e0c62ef890b4da211792d3b7039bdb49ae3"
   },
   "source": [
    "And calculate the __AUC__. Quick quiz: what does AUC stand for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ca5cf9a346ee339d3a5133b92ae4c80fcccf2e2"
   },
   "outputs": [],
   "source": [
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Predict for yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the values for the survey questions below and see what the model predicts for you!\n",
    "\n",
    "* `walk`/`run` should be set to either `0` for no, or `1` for yes\n",
    "* `distance` should be set to a `float` number\n",
    "* The `color_*` should be set to `1` for your favorite, and `0` for the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "24d613abb60bb713089e3474e23323260e70b64b"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame([{\n",
    "    'walk': 1,\n",
    "    'run': 0,\n",
    "    'distance': 8.5,\n",
    "    'color_red': 1,\n",
    "    'color_green': 0,\n",
    "    'color_blue': 0\n",
    "}])\n",
    "\n",
    "prediction = model.predict(data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that's not very interesting. Since this is a binary classifier by nature, the result will be a boolean value. So, let's render this a bit more visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prediction[0]:\n",
    "    animal = 'dog'\n",
    "    pic = 'sparky.png'\n",
    "else:\n",
    "    animal = 'cat'\n",
    "    pic = 'penny.png'\n",
    "    \n",
    "img=mpimg.imread(pic)\n",
    "imgplot = plt.imshow(img)\n",
    "plt.grid(False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title(\"We predict that you're a %s person!\" % animal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Did it get the answer right for you? Probably not, but the data the model is trained from is essentially random, so the results are as well. The Random Forest algorithm did its best to find a pattern and split the data along the nodes, but it's trying to find a signal in data that is only noise.\n",
    "\n",
    "In this lab, we've demonstrated how you can turn survey data into predictions using scikit-learn. Using real data from a properly designed survey, you can very quickly get pretty good results.\n",
    "\n",
    "Go ahead. Try a few more predictions for fun. You know you want to!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
