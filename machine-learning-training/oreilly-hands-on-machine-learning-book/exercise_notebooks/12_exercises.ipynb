{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09fe9a6b-a914-4520-addd-da193953f350",
   "metadata": {},
   "source": [
    "Chapter 12: Custom Models and Training with TensorFlow\n",
    "\n",
    "Chapter 12 exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22bc475-95f8-4657-bf3f-c4088f0f0e14",
   "metadata": {},
   "source": [
    "1. How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular deep learning libraries?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd5b5f2-ebae-4680-b26d-4644e682cb80",
   "metadata": {},
   "source": [
    "-> TensorFlow a powerful library for numerical computations, particularly well suited and fine-tuned for large-scale machine learning\n",
    "\n",
    "->  TensorFlow core is very similar to Numpy, but with GPU support, optimizations for speed and memory usage, compulation graph analysis, portable graphs, reverse-mode autodiff, excellent optimizers such as RMSProp and Nadam, and powerful APIs including tensorflow Keras implementation (tf.keras), data loading and preprocessing ops (tf.data, tf.io, etc), image processing (tf.image), signal processing ops (tf.signal), and more\n",
    "\n",
    "-> Other popular Deep Learning libraries include PyTorch, MXNet, Microsoft Cognitive Toolkit, Theano, Caffe2, and Chainer.\n",
    "\n",
    "page 408: TensorFlow a powerful library for numerical computations, particularly well suited and fine-tuned for large-scale machine learning (but you can use it for anything that requires heavy computations).\n",
    "\n",
    "page 404: \n",
    "TensorFlow core feature summary:\n",
    " - core is very similar to Numpy, but with GPU support\n",
    " - compulation graph analysis: extracts the computational graph from a python function, optimizes it, and running it efficiently \n",
    " - portable: computation graphs can be exported in a portable format, so you can train a TensorFlow model in one environment (e.g. python on Linux), and run it on another (e.g. using Java on Android)\n",
    " - autodiff: implements reverse-mode autodiff and provides excellent optimizers, such as RMSProp and Nadam\n",
    "\n",
    "TensorFlow additional features built on the core features:\n",
    " - keras, data loading and preprocessing ops (tf.data, tf.io, etc), image processing (tf.image), signal processing ops (tf.signal), and more\n",
    "\n",
    "__book answer__: TensorFlow is an open-source library for numerical computation, particularly well suited and fine-tuned for large-scale Machine Learning. Its core is similar to NumPy, but it also features GPU support, support for distributed computing, computation graph analysis and optimization capabilities (with a portable graph format that allows you to train a TensorFlow model in one environment and run it in another), an optimization API based on reverse-mode autodiff, and several powerful APIs such as tf.keras, tf.data, tf.image, tf.signal, and more. Other popular Deep Learning libraries include PyTorch, MXNet, Microsoft Cognitive Toolkit, Theano, Caffe2, and Chainer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d90963-a80a-489b-8e34-2063631013bd",
   "metadata": {},
   "source": [
    "2. Is TensorFlow a drop-in replacement for Numpy? What are the main differences between the two?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357f8b16-5da4-4145-bf48-d46948544465",
   "metadata": {},
   "source": [
    "-> TensorFlow offers similar functionality to Numpy, it is not a drop-in replacement for Numpy.\n",
    "\n",
    "-> Tensflow and Numpy differences include: \n",
    " - a tensor is similar to a ndarray, but it can also hold a scalar;\n",
    " - numpy uses 64-bit precision by default, and TensorFlow uses 32-bit by default;\n",
    " - function names are not always the same (tensorflow function names: tf.reduce_mean(), tf.reduce_sum(), tf_reduce_max, and tf.math.log() which are generally equivalent to Numpy: np.mean(), np.sum(), np.max(), np,log());\n",
    " - some functions do not behave in same way, e.g. tf.transpose(t) creates a new tensor with its own copy of the transposed data while  Numpy t.T just transpose the view on the same data\n",
    " - Numpy ndarrays are mutable, while TensorFlow tf.constant() creates an immutable view. Note: tf.variable() can create a mutable values\n",
    "\n",
    "page 407:\n",
    "Tensors:\n",
    " - TensorFlow API revolve around tensors which flow from operation to operation\n",
    " - a tensor is similar to a Numpy ndarray; it is usually a multidimensional array, but it can also hold a scalar (simple value such as 42)\n",
    "\n",
    "page 408:\n",
    "Tensor flow operations:\n",
    " - create a tensor with 'tensor.constant()'\n",
    " - 'shape' and 'dtype' work on tensors\n",
    " - indexing works much like Numpy: e.g. t[:, 1:],   t[..., 1, tf.newaxis]\n",
    " - math operations include: tf.add(), tf.multiply(), tf.square(), tf.exp(), tf.sqrt(), \n",
    " - Numpy similar operations include: tf.reshape(), tf.squeeze(), tf.tile()\n",
    " - some tensor operation functions have different names from Numpy including: tf.reduce_mean(), tf.reduce_sum(), tf_reduce_max, tf.math.log() are generally equivalent to np.mean(),        np.sum(),        np.max(),      np,log()\n",
    " - tf.transpose(t) functions similar to numpy t.T, but tensor creates a new tensor\n",
    "\n",
    "__book answer__: Although TensorFlow offers most of the functionalities provided by NumPy, it is not a drop-in replacement, for a few reasons. First, the names of the functions are not always the same (for example, `tf.reduce_sum()` versus `np.sum()`). Second, some functions do not behave in exactly the same way (for example, `tf.transpose()` creates a transposed copy of a tensor, while NumPy's `T` attribute creates a transposed view, without actually copying any data). Lastly, NumPy arrays are mutable, while TensorFlow tensors are not (but you can use a `tf.Variable` if you need a mutable object)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e52eaf2-7cfb-4ebb-a487-f4e81ff67ce7",
   "metadata": {},
   "source": [
    "3. Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd45c1a-dcd1-4b1e-9531-b2da2cb95016",
   "metadata": {},
   "source": [
    "-> On my 64-bit Windows 10 laptop, both return a tensor containing the integers 0 to 9 of dtype of 32-bit integer (as can be seen below). Although numpy should defaults to 64-bit, it is default to 32-bit on Windows 10 64-bit host.  \n",
    "\n",
    "https://stackoverflow.com/questions/36278590/numpy-array-dtype-is-coming-as-int32-by-default-in-a-windows-10-64-bit-machine\n",
    "In Microsoft C, even on a 64 bit system, the size of the long int data type is 32 bits. (See, for example, https://msdn.microsoft.com/en-us/library/9c3yd98k.aspx.) Numpy inherits the default size of an integer from the C compiler's long int.\n",
    "\n",
    "__book answer__: Both `tf.range(10)` and `tf.constant(np.arange(10))` return a one-dimensional tensor containing the integers 0 to 9. However, the former uses 32-bit integers while the latter uses 64-bit integers. Indeed, TensorFlow defaults to 32 bits, while NumPy defaults to 64 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3d0c173-b5ea-4233-b791-0141390f41db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eacb10d4-51eb-47ef-a0b5-462eb4a53341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a7e644b-18d8-478e-aeb6-04e95881b5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72f0c109-e48a-4b7d-8e78-8f528795cfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(np.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85d41cb2-b504-48ca-a526-0185393cacd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sysinfo.platform_bits: 64\n",
      "platform.architecture(): ('64bit', 'WindowsPE')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import platform\n",
    "\n",
    "print(f'sysinfo.platform_bits: {sysinfo.platform_bits}') \n",
    "print(f'platform.architecture(): {platform.architecture()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f23690f-89b3-446b-84c9-12cfba48300e",
   "metadata": {},
   "source": [
    "4. Can you name six other data structures available in TensorFlow, beyond regular tensors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39836fdb-f909-4e0c-8417-802beacdd9cc",
   "metadata": {},
   "source": [
    "-> Six other tensorflow data structures: Spare tensors (tf.SparseTensors), Tensor Arrays (tf.TensorArrays), Ragged tensors (tf.RaggedTensors), String tensors (tf.string), Sets, and Queues (tf.queue). Sets and strings are represented as regular tensors with special functions to manipulate them (in tf.s)\n",
    "\n",
    "\n",
    "page 411:\n",
    "\n",
    ">Spare tensors (tf.SparseTensors)\n",
    " - efficiently represented tensors containing mostly zeros\n",
    " - the tf.sparse package contains operations for sparse tensors\n",
    ">Tensor Arrays (tf.TensorArrays)\n",
    " - Are a lists of tensors. They all have fixed lengths by default, but can optionally be made extensible\n",
    ">Ragged tensors (tf.RaggedTensors)\n",
    " - represent lists of tensors, all of the same rank (dimensions) and data type, but varying sizes\n",
    " - the tf.ragged package contains operations for ragged tensors\n",
    ">String tensors (tf.string)\n",
    " - are regular tensors of the type tf.string\n",
    " - the represent 'byte strings', not Unicode strings\n",
    " - the tf.string package contains operations for byte strings and Unicode strings (convert one into the other)\n",
    ">Sets:\n",
    " - Are represented as regular tensors (or sparse arrays).\n",
    " - for example, tf.constant([1,2],[3,4]]) represents two sets [1,2] and [3,4]. More generally, each set is represented by a vector in the tensor's last axis\n",
    " - the tf.sets package contains operations for maniplating sets\n",
    ">Queues\n",
    " - stores tensors across multiple steps\n",
    " - offers various queues: FIFOQueue, PriortyQueue, RandomShuffleQueue, PaddingFIFOQueue\n",
    " - these classes are in the  tf.queue package\n",
    "\n",
    "__book answer__: Beyond regular tensors, TensorFlow offers several other data structures, including sparse tensors, tensor arrays, ragged tensors, queues, string tensors, and sets. The last two are actually represented as regular tensors, but TensorFlow provides special functions to manipulate them (in tf.strings and tf.sets)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3222b06-f6d6-46e8-8302-b0c4ffbfef0f",
   "metadata": {},
   "source": [
    "5. You can define custom loss function by writing a function or by subclassing the 'tf.keras.losses.loss class. When would you use each option?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7614e6c-e2bd-4ee4-b44f-0cdbb1ce5b25",
   "metadata": {},
   "source": [
    "-> In general, you would use a Python custom loss function. If the loss is calculate using labels, predictions, and/or weights, you would implement with a custom loss function. <br>\n",
    "-> If the custom loss function must support some hyperparameters (or any other state), you would need to implement by subclassing the `tf.keras.losses.Loss` and implement the `__init__()` and `call()` methods. If you want the loss function's hyperparameters to be saved, then you must also implement the `get_config()` method. <br>\n",
    "\n",
    "page 424: <br>\n",
    "Defining custom losses base on model internals:\n",
    "- the previous custom losses and metrics solutions were based on the labels and the predictions (and optionally weights)\n",
    "- However, there are cases where you need to define custom loss based on model internals, compute it based on any part of the model you want, then pass the result to the 'add_loss()' method\n",
    "- example case: custom regression MLP composed of stack of 5 hidden layers, plus output layer. \n",
    "  It is also includes a auxilary output on top of the upper hidden layer. \n",
    "  The auxilary output will have a 'reconstruction loss' (mean squared difference between the 'reconstruction' and the inputs).\n",
    "  Reconstruction loss will be added to the main loss.\n",
    "\n",
    "__book answer__:  When you want to define a custom loss function, in general you can just implement it as a regular Python function. However, if your custom loss function must support some hyperparameters (or any other state), then you should subclass the `keras.losses.Loss` class and implement the `__init__()` and `call()` methods. If you want the loss function's hyperparameters to be saved along with the model, then you must also implement the `get_config()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00b75f6-8e64-4613-9218-9619d1e4def5",
   "metadata": {},
   "source": [
    "6. Similarly, you can define a custom metric in a function or as a subclass of 'tf.keras.metrics.Metric'. When would you use each? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3740e892-af77-48f9-9fb5-db7ca4a2550d",
   "metadata": {},
   "source": [
    "-> in general, you would implement a custom metric using a regular Python metric function.<br>\n",
    "-> However, if your custom metric needs to support some hyperparameters (or any other state),  it would need to implement by subclassing the `tf.keras.metrics.Metric` and implementing the `__init__()`, `update_state()`, and `reset_states()` methods.<br>\n",
    "-> Additionally, if the custom metric cannot be averaged over each batch and instead needs to be calculate over each epoch (e.g. custom streaming/statefull metrics), then it would also need to implement by subclassing the 'tf.keras.Metrics.metric' and implementing the `__init__()`, `update_state()`, and `reset_states()` methods <br>\n",
    "-> Finally, if you want the custom metrics function's hyperparameters to be saved, then you must also need implement the get_config() method in addition to implementing the custom metric as a subclassing of `tf.keras.metrics.Metric`\n",
    "\n",
    "page 419:\n",
    "Custom metric using a simple function vs Custom streaming metric (or stateful metric)\n",
    " - keras automatically calls simple metric function for each batch, and it keeps track of the mean during each epoch\n",
    " - The only benefit of our HuberMetric class (subclass of tf.keras.metrics.Metric') is that the 'threshold' (custom) variable will be saved\n",
    " - some metrics like 'precision' can not be simply averaged over batches; in those cases, there is no option that to implement a stream metric\n",
    "\n",
    "__book answer__: Much like custom loss functions, most metrics can be defined as regular Python functions. But if you want your custom metric to support some hyperparameters (or any other state), then you should subclass the `keras.metrics.Metric` class. Moreover, if computing the metric over a whole epoch is not equivalent to computing the mean metric over all batches in that epoch (e.g., as for the precision and recall metrics), then you should subclass the `keras.metrics.Metric` class and implement the `__init__()`, `update_state()`, and `result()` methods to keep track of a running metric during each epoch. You should also implement the `reset_states()` method unless all it needs to do is reset all variables to 0.0. If you want the state to be saved along with the model, then you should implement the `get_config()` method as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20467852-84ea-486b-9fd1-461b800dfa88",
   "metadata": {},
   "source": [
    "7. When should you create a custom layer versus a custom model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc9e41d-22ef-4efd-ac36-c335a3a57fb1",
   "metadata": {},
   "source": [
    "-> Layers are reusable blocks (objects) in your model. If you need custom functionality in these reusable blocks used inside your model, these should be implmented using custom layers. <br>\n",
    "-> The model is the object to be trained. If how the model is trained needs to be customized, then it needs to be implemented with a custom model. For example, if you need to create custom loss metric based on the model's internals, then you need to implement a custom model.  \n",
    "\n",
    "\n",
    "page 424: <br>\n",
    "Model Class\n",
    " - is a subclass of the 'Layer' class, so models can be used exactly like layers\n",
    " - Model have some additional functionalities (than layers), including of course compile(), fit(), evaluate(), and predict() methods, plus 'get_layer()' method and 'save()' method\n",
    " - layers should subclass the 'Layer' class and models should subclass the 'Model()' class\n",
    "\n",
    "page 424: <br>\n",
    "Defining custom losses base on model internals <br>\n",
    " - the previous custom losses and metrics solutions were based on the labels and the predictions (and optionally weights)\n",
    " - However, there are cases where you need to define custom loss based on model internals, compute it based on any part of the model you want, then pass the result to the 'add_loss()' method\n",
    " - example case: custom regression MLP composed of stack of 5 hidden layers, plus output layer. \n",
    "   It is also includes a auxilary output on top of the upper hidden layer. \n",
    "   The auxilary output will have a 'reconstruction loss' (mean squared difference between the \n",
    "   'reconstruction' and the inputs).\n",
    "   Reconstruction loss will be added to the main loss.<br>\n",
    "\n",
    "__book answer__:  You should distinguish the internal components of your model (i.e., layers or reusable blocks of layers) from the model itself (i.e., the object you will train). The former should subclass the `keras.layers.Layer` class, while the latter should subclass the `keras.models.Model` class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695e4e0a-9137-40ed-9028-235b8ab82535",
   "metadata": {},
   "source": [
    "8. What are some use cases that require writing your own custom training loop?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14bffbe-23fa-479e-82ee-db9b7214f470",
   "metadata": {},
   "source": [
    "-> Custom training loop should only be used when the models `fit()` method is not flexible enough for what you need to do during training. Custom training loops are complex and error prone, so they should be avoided where possible. It should be noted that there are means to customize Training without custom training loops. These include custom losses, custom regularizers, custom activation funtion, and so. \n",
    "\n",
    "page 415: <br>\n",
    "Custom Keras functionalities\n",
    " - Most of Keras functionalities, such as losses, regularizers, constraints, initializers, metrics, activation functions, layers, and even full models can be customized in same way as the previous section showed for loss functions\n",
    " - most of the time, you will just need to write a simple function with the appropriate inputs and outputs\n",
    " - in the below example: \n",
    " - the activation function will be applied to the output of this Dense layer, and its results will be passed on the to the next layer\n",
    " - the layer's weights will be initialized by the value returned by the initializer\n",
    " - at each training step the weights will be passed the regularization function to compute the regularization loss, which will be added to the main loss to get the final loss for training\n",
    " - the constraint function will be called after each training step, and teh layer's weights will be replaced by the constrained weights <br>\n",
    "\n",
    "page 430: <br>\n",
    "Custom loop training\n",
    " - used when the 'fit()' method may not be flexible enough for what you need to do\n",
    " - example: Wide & Deep uses two different optimizers: one for the wide path and the other for the deep path\n",
    " - Unless you really need the extra flexibility, you should use the 'fit()' method <br>\n",
    "\n",
    "__book answer__: Writing your own custom training loop is fairly advanced, so you should only do it if you really need to. Keras provides several tools to customize training without having to write a custom training loop: callbacks, custom regularizers, custom constraints, custom losses, and so on. You should use these instead of writing a custom training loop whenever possible: writing a custom training loop is more error-prone, and it will be harder to reuse the custom code you write. However, in some cases writing a custom training loop is necessary⁠—for example, if you want to use different optimizers for different parts of your neural network, like in the [Wide & Deep paper](https://homl.info/widedeep). A custom training loop can also be useful when debugging, or when trying to understand exactly how training works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a560577-89a5-4719-bb81-6c30c3a37b9f",
   "metadata": {},
   "source": [
    "9. Can custom Keras components contain arbitrary Python code, or must they be convertible to TF functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387b546b-b312-4a99-aece-cc5539c0b42b",
   "metadata": {},
   "source": [
    "-> For performance, portability, and functionality reasons, python code in Keras components should be convertible to TF functions following the rules provide on pages 437 - 438 (and below). <br>\n",
    "-> However, you can wrap arbitrary Python code in a `tf.py_function()` operation, but doing so will hinder performance.  You can tell Keras not to convert your python functions to TF functions when creating a custom layer or custom model by setting `dynamic=True` or set `run_eagerly=True` when calling the model's `compile()` method. Again, this will hinder performance. \n",
    "\n",
    "page 434: <br>\n",
    "tf.function() with Accelerated Linear Algebra (XLA) <br>\n",
    " - if you set jit_compile=True when calling tf.function(), then the TensorFlow will use Accelerated Linear Algrebra (XLA) to compile dedicated kernels for your graph, often fusing multiple operations\n",
    "   - for example, XLA can compute tf.reduce_sum(a * b + c) in one step instead of 3 steps\n",
    "\n",
    "custom functions with kera models\n",
    " - when you write a custom loss function, a custom metric function, a custom layer, or any other custom function and use it with a Kera model, Keras automatically converts your function into a TF function (no need to use tf.function())\n",
    " - if you want Keras to use XLA, you need to just set jit_compile=True when call the compile() method\n",
    " - you can tell Keras not to convert your python functions to TF functions when creating a custom layer or custom model by setting `dynamic=True` or set `run_eagerly=True` when calling the model's `compile()` method <br>\n",
    "\n",
    "\n",
    "page 437 - 438: <br>\n",
    "tf.function:\n",
    "   - converting a Python function that performs TensorFlow operations into a TF function usually just require decorating it with: '@tf.function'\n",
    "\n",
    "Converting to 'tf.function' rules:\n",
    "- External libraries\n",
    "   - external libraries including Numpy and std library will run only during tracing; they will not be part of the graph\n",
    "   - examples: use tf.reduce_sum() instead of 'np.sum()', tf.sort() instead of built-in 'sorted()' function, and so on\n",
    "\n",
    "- random numbers\n",
    "   - if you define a TF function f(x) that just returns 'np.random.rand()', a random number will be generated when the function is traced, so f(tf.constant(2.) and f(tf.constant(3.) will generate the same random number, but f(tf.constant([2., 3.])) will return a different number (because input shape is different)\n",
    "   - to generate a random number each call, replace 'np.random.rand()' with tf.random.uniform([]) code side effects\n",
    "   - if your non-TensorFlow code has side-effects (e.g. logging, updating python counter), side effect will occur only when function is traced\n",
    "- wrap python code in 'tf.py_function()'\n",
    "   - you can wrap arbitrary Python code in a 'tf.py_function()' operation, but doing so will hinder performance\n",
    "\n",
    "- Calling other Python Functions or TF functions\n",
    "   - you can call other python functions or TF functions, but they should follow the same rules as TensorFlow will capture their operations in the computation graphs\n",
    "   - other functions do NOT need to be decorated\n",
    "\n",
    "- TensorFlow variables\n",
    "   - if the function creates a TensorFlow variable (or dataset, queue, etc.), it must do so upoon the very first call \n",
    "   - it is preferable to variables outside of the TF function (e.g. in buld() method or custom layer\n",
    "   - if you want to assign a new value to a variable, may sure you call its 'assign()' method instead of '=' operator\n",
    "\n",
    "- Python Source code\n",
    "   - source code of your python function should be available to tensorFlow\n",
    "   - if source code is unavailable, then the graph generation process will fail or have limited functionality\n",
    "\n",
    "- Vectorized implementations\n",
    "   - for performance reasons, you should prefer a vectorized implementation whenever you can, rather than using loops\n",
    "\n",
    "\n",
    "__book answer__: Custom Keras components should be convertible to TF Functions, which means they should stick to TF operations as much as possible and respect all the rules listed in Chapter 12 (in the _TF Function Rules_ section). If you absolutely need to include arbitrary Python code in a custom component, you can either wrap it in a `tf.py_function()` operation (but this will reduce performance and limit your model's portability) or set `dynamic=True` when creating the custom layer or model (or set `run_eagerly=True` when calling the model's `compile()` method)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7effe337-ea67-43d4-817d-d99e483f5c8a",
   "metadata": {},
   "source": [
    "10. What are the main rules to respect if you want a function to be convertible to a TF function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf02db4d-051e-4f38-8d53-c1bf27d37919",
   "metadata": {},
   "source": [
    "-> see __TF Function Rules__ section on pages 437 - 438 (and summarized in answer to question 9). <br>\n",
    "\n",
    "__book answer__: Please refer to Chapter 12 for the list of rules to respect when creating a TF Function (in the _TF Function Rules_ section)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875dc075-9dbe-4c60-9440-f363be349f25",
   "metadata": {},
   "source": [
    "11. When would you need to create dynamic Keras model? How do you do that? Why not make all your model dynamic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68942b32-d95c-4f7a-9479-ad88e353cb65",
   "metadata": {},
   "source": [
    "-> Creating a dynamic Keras model can be useful for debugging, as it will not compile any custom component to a TF Functions. It can also be useful if you want to include arbitrary Python code in your model (or in your training code), including calls to external libraries. <br>\n",
    "-> To make a model dynamic, you must set `dynamic=True` when creating it (e.g. model = MyModel(dynamic=True)). Alternatively, you can set `run_eagerly=True` when calling the model's `compile()` method (e.g. model.compile(loss=my_mse, optimizer=\"nadam\", run_eagerly=True). \n",
    "-> Making a model dynamic prevents Keras from using any of TensorFlow's graph features, so it will slow down training and inference, and you will not have the possibility to export the computation graph, which will limit your model's portability.\n",
    "\n",
    "\n",
    "page 434: <br>\n",
    "custom functions with kera models\n",
    " - when you write a custom loss function, a custom metric function, a custom layer, or any other custom function and use it with a Kera model, Keras automatically converts your function into a TF function (no need to use tf.function())\n",
    " - if you want Keras to use XLA, you need to just set jit_compile=True when call the compile() method\n",
    " - you can tell Keras not to convert your python functions to TF functions when creating a custom layer or custom model by setting 'dynamic=True' or set 'run_eagerly=True' when calling the model's compile() method <br>\n",
    "\n",
    "https://keras.io/2.15/api/layers/base_layer/<br>\n",
    "Layer class <br>\n",
    "tf_keras.layers.Layer(trainable=True, name=None, dtype=None, dynamic=False, **kwargs) <br>\n",
    "The base Layer class __dynamic__ argument: <br>\n",
    "dynamic: Set this to True if your layer should only be run eagerly, and should not be used to generate a static computation graph. This would be the case for a Tree-RNN or a recursive network, for example, or generally for any layer that manipulates tensors using Python control flow. If False, we assume that the layer can safely be used to generate a static computation graph.\n",
    "\n",
    "Model training APIs <br>\n",
    "compile method <br>\n",
    "Model.compile( optimizer=\"rmsprop\", loss=None, loss_weights=None, metrics=None, weighted_metrics=None, run_eagerly=False, steps_per_execution=1, jit_compile=\"auto\", auto_scale_loss=True,) <br>\n",
    "\n",
    "The Model `compile()` method's __run_eagerly__ argument: <br>\n",
    "run_eagerly: Bool. If True, this model's forward pass will never be compiled. It is recommended to leave this as False when training (for best performance), and to set it to True when debugging.\n",
    "\n",
    "\n",
    "__book answer__: Creating a dynamic Keras model can be useful for debugging, as it will not compile any custom component to a TF Function, and you can use any Python debugger to debug your code. It can also be useful if you want to include arbitrary Python code in your model (or in your training code), including calls to external libraries. To make a model dynamic, you must set `dynamic=True` when creating it. Alternatively, you can set `run_eagerly=True` when calling the model's `compile()` method. Making a model dynamic prevents Keras from using any of TensorFlow's graph features, so it will slow down training and inference, and you will not have the possibility to export the computation graph, which will limit your model's portability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91b2741-b469-4d6c-b654-4b85963d39fb",
   "metadata": {},
   "source": [
    "__12.__ Implement a custom layer that performs 'layer normalization' (we will use this type of layer in Chapter 15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9ca027a-9c92-4e6c-98ce-4a76bfd13e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c40f3f-e0fa-4624-b42e-97957afcd2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\" / \"deep\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8a12d5-aad6-4da5-8c7d-07ab24a71d4f",
   "metadata": {},
   "source": [
    "__12 a.__\n",
    "_Exercise: The `build()` method should define two trainable weights *α* and *β*, both of shape `input_shape[-1:]` and data type `tf.float32`. *α* should be initialized with 1s, and *β* with 0s._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e03d7c2-e5d8-4688-8851-ad15483f9830",
   "metadata": {},
   "source": [
    "__12 b.__\n",
    "_Exercise: The `call()` method should compute the mean_ μ _and standard deviation_ σ _of each instance's features. For this, you can use `tf.nn.moments(inputs, axes=-1, keepdims=True)`, which returns the mean μ and the variance σ<sup>2</sup> of all instances (compute the square root of the variance to get the standard deviation). Then the function should compute and return *α*⊗(*X* - μ)/(σ + ε) + *β*, where ⊗ represents itemwise multiplication (`*`) and ε is a smoothing term (small constant to avoid division by zero, e.g., 0.001)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb0c7df8-2e65-4d62-9330-2816071f99c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, eps=0.001, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.alpha = self.add_weight(name=\"alpha\", shape=batch_input_shape[-1:], initializer=\"ones\")\n",
    "        self.beta = self.add_weight(name=\"beta\", shape=batch_input_shape[-1:], initializer=\"zeros\")\n",
    "\n",
    "\n",
    "    def call(self, X):\n",
    "        mean, variance = tf.nn.moments(X, axes=-1, keepdims=True)\n",
    "        return self.alpha * (X - mean) / (tf.math.sqrt(variance + self.eps)) + self.beta \n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"eps\": self.eps}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f597be30-e238-4dd4-814c-b7ca3ba64635",
   "metadata": {},
   "source": [
    "Note that making ε a hyperparameter (eps) was not compulsory. Also note that it's preferable to compute tf.sqrt(variance + self.eps) rather than tf.sqrt(variance) + self.eps. Indeed, the derivative of sqrt(z) is undefined when z=0, so training will bomb whenever the variance vector has at least one component equal to 0. Adding ε within the square root guarantees that this will never happen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036dc302-4e58-4277-8e8d-3bf68935a3e9",
   "metadata": {},
   "source": [
    "__12 c.__\n",
    "_Exercise: Ensure that your custom layer produces the same (or very nearly the same) output as the `tf.keras.layers.LayerNormalization` layer._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec311518-a077-40b0-bc20-93159d42a530",
   "metadata": {},
   "source": [
    " Train it on the California housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2d71218-d7a7-4e3e-8168-dd59459f0824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f709c2b0-c464-499d-8f4c-db1057468cc2",
   "metadata": {},
   "source": [
    "Let's create one instance of each class, apply them to some data (e.g., the training set), and ensure that the difference is negligeable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54702b18-c287-43af-bff6-e23f706a89bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pat\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\layer_normalization.py:328: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.44626e-08>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train.astype(np.float32)\n",
    "\n",
    "custom_layer_norm = LayerNormalization()\n",
    "keras_layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "tf.reduce_mean(tf.keras.losses.mean_absolute_error(\n",
    "    keras_layer_norm(X), custom_layer_norm(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b1a9a-9f19-45ab-b9ec-081b4071c1be",
   "metadata": {},
   "source": [
    "Yep, that's close enough. To be extra sure, let's make alpha and beta completely random and compare again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89b34abe-f07d-4034-a619-fd41c6d07242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.6339667e-08>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "random_alpha = np.random.rand(X.shape[-1])\n",
    "random_beta = np.random.rand(X.shape[-1])\n",
    "\n",
    "custom_layer_norm.set_weights([random_alpha, random_beta])\n",
    "keras_layer_norm.set_weights([random_alpha, random_beta])\n",
    "\n",
    "tf.reduce_mean(tf.keras.losses.mean_absolute_error(\n",
    "    keras_layer_norm(X), custom_layer_norm(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15374584-3037-4c23-8b6a-8ca51e63d999",
   "metadata": {},
   "source": [
    "Still a negligeable difference! Our custom layer works fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980912ae-59a1-4b48-9753-d61da0064bfa",
   "metadata": {},
   "source": [
    "__13.__ Train a model using a custom training loop to tackle the Fashion MNIST dataset\n",
    "_The Fashion MNIST dataset was introduced in Chapter 10._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca4c61-1330-4333-a56e-ff1cb68387ad",
   "metadata": {},
   "source": [
    "__13 a.__\n",
    "_Exercise: Display the epoch, iteration, mean training loss, and mean accuracy over each epoch (updated at each iteration), as well as the validation loss and accuracy at the end of each epoch._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "492cad17-72f5-4c6a-810b-1456577c20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train_full = X_train_full.astype(np.float32) / 255.\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test.astype(np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc281542-a050-4e4b-867b-e15a012dd491",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9987f8db-f244-4fd1-8ee7-3df2e7337421",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd2d7ef-a5a9-452d-aaec-42c8b4563ee5",
   "metadata": {},
   "source": [
    "Note: previously installed for lesson 10.\n",
    "\n",
    "pre-pydot installation message from below 'tf.keras.utils.plot_model()' call:\n",
    "\n",
    "You must install pydot (pip install pydot) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
    "\n",
    "To install:\n",
    "\n",
    "!pip install pydot\n",
    "\n",
    "restart kernel (Kernel -> Restart Kernel)\n",
    "\n",
    "In \"06_decision_trees.ipynb', graphviz was installed using:\n",
    "\n",
    "conda install anaconda::graphviz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88578e3b-41c3-407d-89ff-87edc72408a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5f955a5-936c-4416-8097-969d5a7c3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = tf.keras.metrics.Mean()\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d5a60541-ed6e-4ad9-b86d-388cd1f976c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4350b8c0-4866-44d1-ad14-a5a9ff4555d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fbb45d2a934679ba1ab4b3d4ba6fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61f54f4c6a64a78b7991cf2035b600f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22963b00181847129049e0673a2055f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e20ef2889094caaba9159bc3c5cc41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb706b857114645b0e633d6d6385a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9442ff2cdc74a9c84679cc78970123a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=f\"Epoch {epoch}/{n_epochs}\") as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))\n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(X_valid)\n",
    "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status[\"val_accuracy\"] = np.mean(tf.keras.metrics.sparse_categorical_accuracy(\n",
    "                tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e01814b-5c08-4cf5-975a-1753f9bafb77",
   "metadata": {},
   "source": [
    "__13 b.__\n",
    "_Exercise: Try using a different optimizer with a different learning rate for the upper layers and the lower layers._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "03bb8ac7-01ff-4277-8c73-16c367d57305",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "13c5f052-3c0d-4cb5-9b9e-8acb7aedb4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_layers = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "])\n",
    "upper_layers = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model = tf.keras.Sequential([\n",
    "    lower_layers, upper_layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfb02e14-5adb-451e-9eb3-502e5feda6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
    "upper_optimizer = tf.keras.optimizers.Nadam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7141506-b7df-4e88-a442-19ef5063ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = tf.keras.metrics.Mean()\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ca71b120-813e-4106-8bc2-a4d7a20804bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f388368e3f4ec59851867b82c07244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a24ee242374b8cb2c81397ddf4ea24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a88f7549c144d3898052fe983f2c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56602d2bd117452ca184338c637d031f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f004a582c1c34e19bf847f37d56846e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f837fc0709a46f0a729590f9d91a8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=f\"Epoch {epoch}/{n_epochs}\") as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape(persistent=True) as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                \n",
    "                for layers, optimizer in ((lower_layers, lower_optimizer),\n",
    "                                          (upper_layers, upper_optimizer)):\n",
    "                    gradients = tape.gradient(loss, layers.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, layers.trainable_variables))\n",
    "                del tape\n",
    "                \n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))\n",
    "                \n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                \n",
    "                steps.set_postfix(status)\n",
    "            \n",
    "            y_pred = model(X_valid)\n",
    "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status[\"val_accuracy\"] = np.mean(tf.keras.metrics.sparse_categorical_accuracy(\n",
    "                tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "            \n",
    "            steps.set_postfix(status)\n",
    "        \n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6d2528-8cf1-4f41-82b6-a0566faac5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
